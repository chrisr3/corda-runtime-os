# Default Kafka properties. Settings in this file are used if no property is specified by the user. If no property is
# specified here, then the Kafka default is used. Note that some set defaults here are the same as those in the enforced
# configuration, as a precaution.

# Common defaults across all consumers and producers
common {
    # Default connection server. Note that this will need overriding in the majority of cases.
    bootstrap.servers = "localhost:9092"
}

# Defaults for all consumers.
consumer = ${common} {
    # This ensures a default where connection with no offset for a consumer group does not result in an exception.
    auto.offset.reset = earliest
    # Ensures that messages from uncommitted transactions are not visible. This is required to meet transactionality
    # requirements on patterns that need it.
    isolation.level = read_committed
    # Force consumers to commit their offsets manually. Again required for transactionality.
    enable.auto.commit = false
    # The number of records to retrieve in a single batch. Note that the batch may be smaller than this if Kafka does
    # not have enough data or the batch data limit is met before this many records are read.
    max.poll.records = 500
    # The minimum number of bytes to wait for before returning a batch of data. Note that less data than this may be
    # returned if fetch.max.wait.ms timeout expires first. Increasing this will increase throughput at the cost of
    # latency.
    fetch.min.bytes = 3000
    # The maximum amount of time a fetch request should block waiting for data before returning. Tuning this up gives a
    # greater chance of filling a batch of messages and increasing throughput, at the cost of additional latency in low
    # data volume scenarios.
    fetch.max.wait.ms = 500
    # Time to allow between polls on a consumer before a rebalance occurs that removes this consumer's partitions.
    max.poll.interval.ms = 100000
    # Timeout of heartbeats between the consumer and the broker. If no heartbeat is received in this timeframe, a
    # rebalance will occur.
    session.timeout.ms = 6000
    # Frequency of heartbeats between the consumer and the broker. Should be no higher than 1/3 of the session timeout.
    heartbeat.interval.ms = 2000
}

# Defaults for all producers.
producer = ${common} {
    # Ensures that messages are sent to the broker exactly once. Note that some configuration settings must be set to
    # compatible values as a result of this. A ConfigException will be raised if these are set to incompatible values.
    enable.idempotence = true
    # Ensures that messages are not lost due to broker failure at inopportune moments. This forces acknowledgements from
    # all in-sync replicas before continuing, which ensures the message has reached at least one broker.
    acks = all
    # The size of the batch to use when buffering records to send. This is the upper limit of the batch size. By
    # increasing this throughput will go up at the cost of latency.
    batch.size = 32000
    # An artificial amount of delay introduced in the publisher to allow for batches of records to build up before
    # publishing. By increasing this published batch sizes will be larger, but it will take longer for each batch to be
    # sent to the broker.
    linger.ms = 50
}

# Roles that particular consumers or producers could be taking. By tying consumers and producers to the roles they are
# performing in the patterns, each can be configured properly to reflect the job they are supposed to do.
roles {
    admin {
        admin = ${common}
    }
    pubsub {
        consumer = ${consumer} {
            # Pubsub consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset = latest
        }
    }
    compacted {
        consumer = ${consumer}
    }
    durable {
        consumer = ${consumer}
        producer = ${producer}
    }
    stateAndEvent {
        stateConsumer = ${consumer}
        eventConsumer = ${consumer}
        producer = ${producer}
    }
    eventLog {
        consumer = ${consumer}
        producer = ${producer}
    }
    rpcSender {
        consumer = ${consumer} {
            # RPC pattern consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset=latest
        }
        producer = ${producer}
    }
    rpcResponder {
        consumer = ${consumer} {
            # RPC pattern consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset = latest
        }
        producer = ${producer}
    }
    publisher {
        producer = ${producer}
    }
}
